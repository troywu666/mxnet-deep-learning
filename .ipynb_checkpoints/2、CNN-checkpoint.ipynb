{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维互相关运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T01:38:36.797382Z",
     "start_time": "2019-05-04T01:38:25.670973Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import autograd as ag\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T09:59:44.867321Z",
     "start_time": "2019-05-04T09:59:44.860316Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr2d(X,K):\n",
    "    h,w=K.shape\n",
    "    Y=nd.zeros((X.shape[0]-h+1,X.shape[1]-w+1))\n",
    "    for i in range(X.shape[0]-h+1):\n",
    "        for j in range(X.shape[1]-w+1):\n",
    "            Y[i,j]=(X[i:i+h,j:j+w]*K).sum()\n",
    "            print(Y[i,j])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T09:59:45.581735Z",
     "start_time": "2019-05-04T09:59:45.563725Z"
    }
   },
   "outputs": [],
   "source": [
    "X = nd.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = nd.array([[0, 1], [2, 3]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T01:51:37.873368Z",
     "start_time": "2019-05-04T01:51:37.867366Z"
    }
   },
   "outputs": [],
   "source": [
    "class Conv2d(nn.Block):\n",
    "    def __init__(self,kernel_size,**kwargs):\n",
    "        super(Conv2d,self).__init__(**kwargs)\n",
    "        self.weight=self.params.get('weight',shape=kernel_size)\n",
    "        self.bias=self.params.get('bias',shape=(1,))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight.data())+self.bias.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过数据学习核数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T02:32:05.579677Z",
     "start_time": "2019-05-04T02:32:05.515634Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import gluon\n",
    "\n",
    "conv2d=nn.Conv2D(1,kernel_size=(1,2))\n",
    "conv2d.initialize()\n",
    "\n",
    "##X=nd.ones((1,1,6,8))\n",
    "##X[:,:,:,2:6]=0\n",
    "##K=nd.array([[1,-1]])\n",
    "##Y=corr2d(X,K)\n",
    "##corr2d只能用在二维数组\n",
    "X=nd.ones((6,8))\n",
    "X[:,4:5]=0\n",
    "K=nd.array([[1,-1]])\n",
    "Y=corr2d(X,K)\n",
    "print(X,K,Y)\n",
    "X=X.reshape((1,1,6,8))\n",
    "Y=Y.reshape((1,1,6,7))\n",
    "\n",
    "for i in range(10):\n",
    "    with ag.record():\n",
    "        Y_hat=conv2d(X)\n",
    "        l=(Y-Y_hat)**2\n",
    "    l.backward()\n",
    "    conv2d.weight.data()[:]-=16e-3 * conv2d.weight.grad()\n",
    "    print('NO.%d, loss:%.3f'%(i+1,l.sum().asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T02:32:09.104062Z",
     "start_time": "2019-05-04T02:32:09.098056Z"
    }
   },
   "outputs": [],
   "source": [
    "print(conv2d.weight.data().reshape((1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充与步长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T09:06:34.584340Z",
     "start_time": "2019-05-04T09:06:34.578334Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "def comp_conv2d(conv2d,X):\n",
    "    conv2d.initialize()\n",
    "    print(X)\n",
    "    X=X.reshape((1,1)+X.shape)\n",
    "    print(X)\n",
    "    Y=conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T09:15:17.577834Z",
     "start_time": "2019-05-04T09:15:17.557821Z"
    }
   },
   "outputs": [],
   "source": [
    "##当卷积核的宽与高相同时\n",
    "conv2d=nn.Conv2D(1,kernel_size=3,padding=1)\n",
    "X=nd.random.uniform(shape=(8,8))\n",
    "comp_conv2d(conv2d,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T09:18:53.530942Z",
     "start_time": "2019-05-04T09:18:53.513929Z"
    }
   },
   "outputs": [],
   "source": [
    "##当卷积核的宽与高不同时\n",
    "conv2d=nn.Conv2D(1,kernel_size=(5,3),padding=(2,1))\n",
    "comp_conv2d(conv2d,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T09:27:31.866876Z",
     "start_time": "2019-05-04T09:27:31.847862Z"
    }
   },
   "outputs": [],
   "source": [
    "conv2d=nn.Conv2D(1,kernel_size=3,padding=1,strides=2)\n",
    "comp_conv2d(conv2d,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T09:55:23.316203Z",
     "start_time": "2019-05-04T09:55:23.296192Z"
    }
   },
   "outputs": [],
   "source": [
    "conv2d=nn.Conv2D(1,kernel_size=(3,5),padding=(0,1),strides=(3,5))\n",
    "comp_conv2d(conv2d,X)\n",
    "##当strides为1时，输出shape为（6,6），所以6/5≈2，因为取不到的值默认为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输入通道及多输出通道"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多输入通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T13:33:16.400822Z",
     "start_time": "2019-05-04T13:33:03.693762Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "import d2lzh as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T13:38:58.483593Z",
     "start_time": "2019-05-04T13:38:58.478588Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X,K):\n",
    "    return nd.add_n(*[d2l.corr2d(x,k) for x,k in zip(X,K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T13:38:59.491208Z",
     "start_time": "2019-05-04T13:38:59.083741Z"
    }
   },
   "outputs": [],
   "source": [
    "X = nd.array([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = nd.array([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多输出通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T13:49:38.973319Z",
     "start_time": "2019-05-04T13:49:38.969315Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X,K):\n",
    "    return nd.stack(*[corr2d_multi_in(X,k) for k in K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T13:50:08.446448Z",
     "start_time": "2019-05-04T13:50:08.244430Z"
    }
   },
   "outputs": [],
   "source": [
    "K = nd.array([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "K=nd.stack(K,K+1,K+2)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T13:50:32.877652Z",
     "start_time": "2019-05-04T13:50:32.855640Z"
    }
   },
   "outputs": [],
   "source": [
    "corr2d_multi_in_out(X,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1X1卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T00:37:01.856481Z",
     "start_time": "2019-05-05T00:37:01.850476Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X,K):\n",
    "    c_i,h,w=X.shape\n",
    "    c_o=K.shape[0]\n",
    "    X=X.reshape((c_i,h*w))\n",
    "    K=K.reshape((c_o,c_i))\n",
    "    Y=nd.dot(K,X)\n",
    "    return Y.shape(c_o,h,w)\n",
    "    ## 计算结果与corr2d_multi_in_out是一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T00:43:56.430506Z",
     "start_time": "2019-05-05T00:43:50.445223Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "def pool2d(X,pool_size,mode='max'):\n",
    "    p_h,p_w=pool_size\n",
    "    Y=nd.zeros((X.shape[0]-p_h+1,X.shape[1]-p_w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=Y[i:i+p_h, j:j+p_h].max()\n",
    "            if mode=='avg':\n",
    "                Y[i,j]=Y[i:i+p_h, j:j+p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T00:51:03.518921Z",
     "start_time": "2019-05-05T00:51:03.509915Z"
    }
   },
   "outputs": [],
   "source": [
    "X=nd.arange(16).reshape((1,1,4,4))\n",
    "\n",
    "##默认情况下，MaxPool2D实例里步幅和池化窗口形状相同\n",
    "pool2d=nn.MaxPool2D(3)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T01:02:48.539115Z",
     "start_time": "2019-05-05T01:02:48.530109Z"
    }
   },
   "outputs": [],
   "source": [
    "##也可以指定步长和填充\n",
    "pool2d=nn.MaxPool2D(3,padding=1,strides=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T01:06:06.291081Z",
     "start_time": "2019-05-05T01:06:06.280075Z"
    }
   },
   "outputs": [],
   "source": [
    "##可以指定非正方形的池化窗口\n",
    "pool2d=nn.MaxPool2D((2,3),padding=(1,2),strides=(2,3))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T02:03:09.803419Z",
     "start_time": "2019-05-05T02:03:09.799416Z"
    }
   },
   "outputs": [],
   "source": [
    "##多通道的池化\n",
    "##在处理多通道输入数据时，池化层对每个输入通道分别池化，而不是像卷积层那样将各通道的输入按通道相加。\n",
    "##这意味着池化层的输出通道数与输入通道数相等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T02:03:58.451991Z",
     "start_time": "2019-05-05T02:03:58.039541Z"
    }
   },
   "outputs": [],
   "source": [
    "X=nd.concat(X,X+1,dim=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T02:04:54.158196Z",
     "start_time": "2019-05-05T02:04:54.151192Z"
    }
   },
   "outputs": [],
   "source": [
    "pool2d=nn.MaxPool2D(3,padding=1,strides=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层块⾥的基本单位是卷积层后接最⼤池化层：卷积层⽤来识别图像⾥的空间模式，最大池化层用来降低卷积层对位置的敏感性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T05:54:38.464931Z",
     "start_time": "2019-05-05T05:54:37.516554Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import loss as gloss,nn\n",
    "from mxnet import autograd as ag, nd, init, gluon\n",
    "import d2lzh as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T11:17:54.223210Z",
     "start_time": "2019-05-05T11:17:54.206198Z"
    }
   },
   "outputs": [],
   "source": [
    "net=nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=6, kernel_size=5, activation=\"sigmoid\"),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Conv2D(channels=3, kernel_size=5, activation='sigmoid'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        ##Dense会默认把批量大小*通道*高*宽的输入转化为（批量大小，通道*高*宽）\n",
    "        nn.Dense(120, activation='sigmoid'),\n",
    "        nn.Dense(84, activation=\"sigmoid\"),\n",
    "        nn.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T11:17:54.919069Z",
     "start_time": "2019-05-05T11:17:54.904060Z"
    }
   },
   "outputs": [],
   "source": [
    "X=nd.random.uniform(shape=(1,1,28,28))\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T11:17:55.802232Z",
     "start_time": "2019-05-05T11:17:55.778220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2 (1, 6, 24, 24)\n",
      "pool2 (1, 6, 12, 12)\n",
      "conv3 (1, 3, 8, 8)\n",
      "pool3 (1, 3, 4, 4)\n",
      "dense3 (1, 120)\n",
      "dense4 (1, 84)\n",
      "dense5 (1, 10)\n"
     ]
    }
   ],
   "source": [
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.name, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T11:17:56.363868Z",
     "start_time": "2019-05-05T11:17:56.313837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[[[ 0.02340986 -0.02542695  0.00313462 -0.0464601  -0.06130169]\n",
      "   [ 0.00785864  0.04357625 -0.02547599 -0.02989651  0.0641294 ]\n",
      "   [ 0.05623106  0.06520281  0.01991272  0.01681762  0.03694163]\n",
      "   [ 0.01644962 -0.02624846  0.067953   -0.04814624  0.05421964]\n",
      "   [ 0.0212054   0.03710979 -0.02280865 -0.02609731 -0.00976703]]]\n",
      "\n",
      "\n",
      " [[[-0.01882454  0.04890709 -0.04182265 -0.06687358 -0.00179926]\n",
      "   [ 0.0412028   0.06865159  0.05940089  0.05770113  0.00087503]\n",
      "   [-0.05343108 -0.04981493 -0.06647336 -0.01452717  0.05580927]\n",
      "   [-0.04914352  0.00520381 -0.05281573 -0.04197342  0.06494782]\n",
      "   [ 0.02431145 -0.02752103  0.02019124 -0.03266478 -0.05290802]]]\n",
      "\n",
      "\n",
      " [[[ 0.02766716  0.05385546  0.04997015  0.03794075 -0.01112941]\n",
      "   [-0.02383709 -0.04507095  0.0415182   0.04732931 -0.02455063]\n",
      "   [-0.06610546 -0.02689645 -0.05595909  0.05993526  0.04935576]\n",
      "   [ 0.06676827  0.02839929  0.00329774 -0.00259714  0.06327092]\n",
      "   [-0.01480274  0.05431951  0.05414863  0.00252455 -0.00738897]]]\n",
      "\n",
      "\n",
      " [[[-0.01781517 -0.02348554  0.02944964  0.01070384 -0.00620992]\n",
      "   [-0.0372966   0.0147298   0.03356358  0.06865687  0.0061165 ]\n",
      "   [ 0.03834827  0.03240123 -0.0232013   0.01431908 -0.05754025]\n",
      "   [ 0.06927506 -0.04411322 -0.03896664  0.00375926  0.0384636 ]\n",
      "   [-0.01160566  0.05622519  0.04209235 -0.03984914  0.06064833]]]\n",
      "\n",
      "\n",
      " [[[-0.02888688  0.06290571  0.03915098  0.02247056  0.02080573]\n",
      "   [-0.04308742  0.05370107 -0.05022512  0.00871635  0.06748699]\n",
      "   [-0.06313995 -0.00723708  0.00949081  0.03226962  0.05822455]\n",
      "   [-0.05141455  0.02652697  0.00094936 -0.02920312 -0.0567621 ]\n",
      "   [-0.02936937 -0.00054065  0.04882869 -0.06862476 -0.03014692]]]\n",
      "\n",
      "\n",
      " [[[-0.06414971 -0.04287929  0.05796821  0.00324678  0.05454147]\n",
      "   [ 0.0692972   0.03816     0.05635434  0.00413588 -0.05221214]\n",
      "   [-0.04671074  0.03804709  0.03334896  0.02324422 -0.04002614]\n",
      "   [-0.00963311 -0.06187775 -0.00087251 -0.02580469  0.01237801]\n",
      "   [ 0.01197369 -0.04353021  0.01145582  0.06033569  0.04637492]]]]\n",
      "<NDArray 6x1x5x5 @cpu(0)>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MaxPool2D' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-b089067e9baa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MaxPool2D' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "for layer in net:\n",
    "    print(layer.weight.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T11:17:58.885385Z",
     "start_time": "2019-05-05T11:17:57.525284Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T11:17:59.003699Z",
     "start_time": "2019-05-05T11:17:58.996693Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net):\n",
    "    n,acc_sum=0,0.0##若将该初始化放到for循环内，将使得每batch_size就归零\n",
    "    for X,y in data_iter:\n",
    "        y_hat=net(X)\n",
    "        y=y.astype('float32')\n",
    "        acc_sum+=(y==y_hat.argmax(axis=1)).sum().asscalar()\n",
    "        n+=y.size\n",
    "    return acc_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T11:28:04.742564Z",
     "start_time": "2019-05-05T11:25:18.610234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "N0.1, train_acc:0.104 , test_acc:0.122 \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-255.22438\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-320.80527\n",
      "nan\n",
      "-317.75357\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-325.85095\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "N0.2, train_acc:0.403 , test_acc:0.641 \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-340.2534\n",
      "nan\n",
      "-354.89383\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-365.1185\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-366.61615\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-345.50793\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-361.58698\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-365.3619\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-371.99786\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-378.0726\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-380.9332\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-370.5387\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-379.13254\n",
      "-392.7205\n",
      "-378.99307\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-404.552\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-397.1137\n",
      "nan\n",
      "-390.63193\n",
      "nan\n",
      "-384.7209\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-394.2513\n",
      "-393.5686\n",
      "nan\n",
      "nan\n",
      "-403.39957\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-402.72076\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-393.34967\n",
      "nan\n",
      "-389.7274\n",
      "-404.04214\n",
      "nan\n",
      "-410.77042\n",
      "nan\n",
      "nan\n",
      "-400.4219\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-400.7861\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-417.35345\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-405.55103\n",
      "nan\n",
      "nan\n",
      "-412.5104\n",
      "nan\n",
      "nan\n",
      "-411.42868\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-410.9509\n",
      "nan\n",
      "-423.5994\n",
      "-423.9197\n",
      "-417.61237\n",
      "nan\n",
      "-411.263\n",
      "nan\n",
      "nan\n",
      "-415.26624\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-423.54904\n",
      "nan\n",
      "-429.20163\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-401.26068\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-160.53731\n",
      "N0.3, train_acc:0.643 , test_acc:0.693 \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-429.08133\n",
      "-413.49396\n",
      "nan\n",
      "nan\n",
      "-417.1934\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-420.68604\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-427.66367\n",
      "nan\n",
      "-437.01584\n",
      "-415.75583\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-424.2354\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-443.76663\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-424.8131\n",
      "nan\n",
      "nan\n",
      "-430.18152\n",
      "-435.1123\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-428.00427\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-417.31073\n",
      "nan\n",
      "-426.7661\n",
      "-431.89713\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-433.29602\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-431.1208\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-438.67557\n",
      "nan\n",
      "nan\n",
      "-432.77042\n",
      "nan\n",
      "nan\n",
      "-429.2193\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-429.27466\n",
      "nan\n",
      "nan\n",
      "-436.06232\n",
      "nan\n",
      "-439.56882\n",
      "nan\n",
      "-429.18445\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-447.35925\n",
      "nan\n",
      "-424.60794\n",
      "-435.5629\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-436.7773\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-440.62183\n",
      "nan\n",
      "-437.4524\n",
      "nan\n",
      "nan\n",
      "-428.35843\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-427.85724\n",
      "-428.77148\n",
      "nan\n",
      "-435.63434\n",
      "nan\n",
      "-416.8579\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-435.6737\n",
      "-430.0633\n",
      "nan\n",
      "-434.6503\n",
      "-452.88147\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-440.6922\n",
      "nan\n",
      "-440.92938\n",
      "nan\n",
      "nan\n",
      "-431.69385\n",
      "-455.268\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-428.8502\n",
      "-443.7444\n",
      "-448.20447\n",
      "nan\n",
      "-446.97614\n",
      "nan\n",
      "nan\n",
      "-465.94424\n",
      "-457.82196\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-439.27545\n",
      "-462.4456\n",
      "nan\n",
      "-457.44086\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-442.71613\n",
      "-451.4966\n",
      "-444.4834\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-443.16818\n",
      "-462.92377\n",
      "-450.03595\n",
      "-459.9505\n",
      "-453.86386\n",
      "nan\n",
      "nan\n",
      "-440.24304\n",
      "nan\n",
      "-435.59668\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-455.16458\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-455.72552\n",
      "nan\n",
      "nan\n",
      "-449.55966\n",
      "nan\n",
      "nan\n",
      "-459.86237\n",
      "-437.80978\n",
      "nan\n",
      "-432.13403\n",
      "-452.8671\n",
      "nan\n",
      "nan\n",
      "-460.31555\n",
      "nan\n",
      "nan\n",
      "-453.17307\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-175.6285\n",
      "N0.4, train_acc:0.705 , test_acc:0.719 \n",
      "-464.36328\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-462.9838\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-452.21933\n",
      "nan\n",
      "-463.1312\n",
      "-432.71237\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-454.98145\n",
      "-453.94846\n",
      "nan\n",
      "nan\n",
      "-458.25815\n",
      "nan\n",
      "nan\n",
      "-447.10614\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-465.628\n",
      "-445.9729\n",
      "-451.74136\n",
      "nan\n",
      "-457.8493\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-430.77426\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-462.96832\n",
      "-470.64896\n",
      "nan\n",
      "-448.0129\n",
      "nan\n",
      "-467.77905\n",
      "-462.45847\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-464.1149\n",
      "-466.5336\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-444.113\n",
      "nan\n",
      "nan\n",
      "-453.68964\n",
      "nan\n",
      "nan\n",
      "-451.76617\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-462.30923\n",
      "-470.57675\n",
      "-468.92883\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-455.46732\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-476.54083\n",
      "-474.28635\n",
      "nan\n",
      "-472.40396\n",
      "nan\n",
      "-444.09357\n",
      "nan\n",
      "-478.11505\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-466.70694\n",
      "nan\n",
      "-454.0674\n",
      "nan\n",
      "-465.59338\n",
      "-475.62015\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-430.89218\n",
      "-462.18378\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-451.0344\n",
      "nan\n",
      "-469.99002\n",
      "-440.0123\n",
      "-462.42642\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-469.5798\n",
      "-447.44034\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-456.4961\n",
      "nan\n",
      "-480.3089\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-475.547\n",
      "-473.60458\n",
      "nan\n",
      "-467.21994\n",
      "-468.31332\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-463.79715\n",
      "nan\n",
      "-474.4432\n",
      "-467.8871\n",
      "-472.42645\n",
      "-475.88248\n",
      "nan\n",
      "nan\n",
      "-462.09576\n",
      "nan\n",
      "-428.40674\n",
      "nan\n",
      "-459.50836\n",
      "nan\n",
      "-453.10205\n",
      "nan\n",
      "-453.3533\n",
      "-452.1939\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-459.2527\n",
      "-472.14938\n",
      "-479.3566\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-473.35492\n",
      "-466.3371\n",
      "-462.08463\n",
      "-447.54855\n",
      "nan\n",
      "nan\n",
      "-468.21524\n",
      "nan\n",
      "-481.77454\n",
      "-459.9933\n",
      "-453.81238\n",
      "-479.53488\n",
      "nan\n",
      "nan\n",
      "-476.3697\n",
      "-479.92203\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-483.08893\n",
      "-465.39124\n",
      "-477.67212\n",
      "nan\n",
      "nan\n",
      "-471.12476\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-460.08264\n",
      "nan\n",
      "nan\n",
      "-474.0238\n",
      "-462.63348\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "-482.60788\n",
      "-462.07538\n",
      "nan\n",
      "-447.31274\n",
      "nan\n",
      "-170.19728\n",
      "N0.5, train_acc:0.734 , test_acc:0.752 \n"
     ]
    }
   ],
   "source": [
    "def entropy_loss(y_hat,y):\n",
    "    ##由于神经网络的前向计算和交叉熵是分开算的，所以容易出现溢出\n",
    "    return -nd.pick(y_hat,y).log()\n",
    "\n",
    "def sgd(lr,params,batch_size):\n",
    "    for param in params:\n",
    "        param[:]-=lr*param.grad/batch_size\n",
    "\n",
    "def train_ch5(net,train_iter,test_iter,trainer,lr,num_epochs,batch_size):\n",
    "    loss=gloss.SoftmaxCrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        n,train_acc=0,0.0\n",
    "        for X,y in train_iter:\n",
    "            with ag.record():\n",
    "                y_hat=net(X)\n",
    "                l=loss(y_hat,y).sum()\n",
    "            ##print(entropy_loss(y_hat,y).sum().asscalar())\n",
    "            ##从该语句可以发现，存在溢出\n",
    "            l.backward()\n",
    "            ##trainer(lr,net.collect_params(),batch_size)##\n",
    "            ##卷积神经网络出来的参数是特殊的参数字典，此处直接用gluon自带的trainer函数##\n",
    "            trainer.step(batch_size)\n",
    "            y=y.astype(\"float32\")\n",
    "            train_acc+=(y_hat.argmax(axis=1)==y).sum().asscalar()##此处若将y_hat用net(X)代替，参数将仍是原来参数\n",
    "            n+=y.size\n",
    "        test_acc=evaluate_accuracy(test_iter,net)\n",
    "        print('N0.%d, train_acc:%.3f , test_acc:%.3f '%(epoch+1,train_acc/n,test_acc))\n",
    "\n",
    "net.initialize(force_reinit=True,init=init.Xavier())\n",
    "lr,num_epochs=0.9,5\n",
    "trainer=gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':lr})\n",
    "train_ch5(net,train_iter,test_iter,trainer,lr,num_epochs,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T05:55:20.109183Z",
     "start_time": "2019-05-05T05:54:42.005Z"
    }
   },
   "outputs": [],
   "source": [
    "gluon.Trainer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T11:13:02.134996Z",
     "start_time": "2019-05-05T11:13:01.727627Z"
    }
   },
   "outputs": [],
   "source": [
    "gloss.SoftmaxCrossEntropyLoss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "gluon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
