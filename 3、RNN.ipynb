{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录\n",
    "!ls /home/aistudio/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看个人持久化工作区文件\n",
    "!ls /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!wget https://zh.d2l.ai/d2l-zh.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!unzip d2l-zh.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\r\n",
      "Built on Tue_Jun_12_23:07:04_CDT_2018\r\n",
      "Cuda compilation tools, release 9.2, V9.2.148\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  1 14:55:56 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 396.37                 Driver Version: 396.37                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:09.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install mxnet-cu92==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install d2lzh==0.8.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use gpu(0)\n"
     ]
    }
   ],
   "source": [
    "import d2lzh as d2l\r\n",
    "ctx = d2l.try_gpu()\r\n",
    "print('will use', ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语言模型数据集\n",
    "## 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'想要有直升'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('data/jaychou_lyrics.txt.zip') as zin:\n",
    "    with zin.open('jaychou_lyrics.txt') as f:\n",
    "        corpus_chars=f.read().decode('utf-8')\n",
    "\n",
    "corpus_chars.replace('\\n',' ')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63282\n",
      "2582\n",
      "[270, 1273, 2121, 1159, 2448, 2212, 49, 270, 1273, 2478, 168, 2559, 2482, 1375, 1277, 2160, 49, 270, 1273, 2478]\n"
     ]
    }
   ],
   "source": [
    "##将转义字符转换成空格\n",
    "corpus_chars=corpus_chars.replace('\\n',' ').replace('\\r',' ')\n",
    "print(len(corpus_chars))\n",
    "\n",
    "##建立字符映射\n",
    "idx_to_char=list(set(corpus_chars))\n",
    "char_to_idx=dict([(char,idx) for idx,char in enumerate(idx_to_char)])\n",
    "vocab_size=len(idx_to_char)\n",
    "print(vocab_size)\n",
    "\n",
    "##将每个字符转换成索引\n",
    "corpus_indices=[char_to_idx[char] for char in corpus_chars]\n",
    "print(corpus_indices[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时序数据的采样\n",
    "### 随机采样\n",
    "*相邻的两个随机小批量在原始序列上的weizhi位置不一定相毗邻*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_iter_random(corpus_indices, batch_size, num_steps, ctx=None):\n",
    "    num_examples=(len(corpus_indices)-1)//num_steps\n",
    "    epoch_size=num_examples//batch_size\n",
    "    example_indices=list(range(num_examples))\n",
    "    random.shuffle(example_indices)\n",
    "    \n",
    "    def _data(pos):\n",
    "        return corpus_indices[pos:pos+num_steps]\n",
    "        \n",
    "    for i in range(epoch_size):\n",
    "        i=i*batch_size\n",
    "        batch_indices=example_indices[i:i+batch_size]\n",
    "        x=[_data(j*num_steps) for j in batch_indices]\n",
    "        y=[_data(j*num_steps+1) for j in batch_indices]\n",
    "        yield nd.array(x, ctx), nd.array(y, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "[[ 6.  7.  8.  9. 10. 11.]\n",
      " [12. 13. 14. 15. 16. 17.]]\n",
      "<NDArray 2x6 @cpu(0)> \n",
      "y: \n",
      "[[ 7.  8.  9. 10. 11. 12.]\n",
      " [13. 14. 15. 16. 17. 18.]]\n",
      "<NDArray 2x6 @cpu(0)> \n",
      "\n",
      "x: \n",
      "[[18. 19. 20. 21. 22. 23.]\n",
      " [ 0.  1.  2.  3.  4.  5.]]\n",
      "<NDArray 2x6 @cpu(0)> \n",
      "y: \n",
      "[[19. 20. 21. 22. 23. 24.]\n",
      " [ 1.  2.  3.  4.  5.  6.]]\n",
      "<NDArray 2x6 @cpu(0)> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_seq=list(range(30))\n",
    "for x,y in data_iter_random(my_seq, batch_size=2, num_steps=6):\n",
    "    print('x:',x,'\\ny:',y,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相邻采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices,batch_size,num_steps,ctx=None):\n",
    "    corpus_indices=nd.array(corpus_indices,ctx=ctx)\n",
    "    data_len=len(corpus_indices)\n",
    "    batch_len=data_len//batch_size\n",
    "    indices=corpus_indices[0:batch_size*batch_len].reshape((batch_size,batch_len))\n",
    "    epoch_size=(batch_size-1)//num_steps\n",
    "    for i in range(epoch_size):\n",
    "        i=i*num_steps\n",
    "        x=indices[:,i:i+num_steps]\n",
    "        y=indices[:,i+1:i+num_steps+1]\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x,y in data_iter_consecutive(my_seq, batch_size=2, num_steps=6):\n",
    "    print('x is ', x, '\\ny is ', y, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN从零实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "import math \n",
    "from mxnet import autograd,nd\n",
    "from mxnet.gluon import loss as gloss\n",
    "import time\n",
    "\n",
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nd.one_hot(nd.array([0,2]), vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_onehot(X, size):\n",
    "    return [nd.onehot(x, size) for x in X.T]\n",
    "\n",
    "X=nd.arange(10).reshape((2,5))\n",
    "inputs=to_onehot(X, vocab_size)\n",
    "len(inputs), inputs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化模型参数\n",
    "$H_{t} = \\phi ( X_{t} W_{xh}+H_{t-1} W_{hh}+b_{h})$\n",
    "\n",
    "$O_t=H_t W_{hq}+b_q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_inputs, num_hiddens, num_outputs=vocab_size, 256, vocab_size\n",
    "ctx=d2l.try_gpu()\n",
    "print('will use', ctx)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        return nd.random.normal(scale=0.01, shape=shape, ctx=ctx)\n",
    "    \n",
    "            W_xh=_one((num_inputs,num_hiddens))\n",
    "            W_hh=_one((num_hiddens,num_hiddens))\n",
    "            b_h=nd.zeros(num_hiddens,ctx=ctx)\n",
    "            \n",
    "            W_hq=_one((num_hiddens,num_outputs))\n",
    "            b_q=nd.zeros(num_outputs,ctx=ctx)\n",
    "            \n",
    "            params=[W_xh, W_hh, b_h, W_hq, b_q]\n",
    "            for param in params:\n",
    "                param.attach_grad()\n",
    "            return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, ctx):\n",
    "    return (nd.zeros(shape=(batch_size, num_hiddens), ctx=ctx), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.4.1 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
